{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLearn Iris Data Loader and DataFrame Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write Code !!\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X,y data Generator...Feature and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Write Code !!\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Test 데이타를 8:2로 비율로 섞고, random_state=42로 지정\n",
    "    X_train, X_test, y_train, y_test 로 각각 할당된 값들을 torch 타입으로 변환 \n",
    "    torch.FloatTensor(), torch.LongTensor 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Write Code !!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True)\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼파라미터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "hidden_size = 56\n",
    "num_classes = 3\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralNetwork  Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module): \n",
    "    def __init__(self, input_size, hidden_size, num_classes): \n",
    "        # Write Code !!\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "       # Write Code !!\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "    \n",
    "        return out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralNetwork  Model Excution , loss, optimizer, backward ..\n",
    "    Forward Propagation and Baward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: [0/100] LOSS: 2.4889726638793945\n",
      "EPOCH: [10/100] LOSS: 0.3820553719997406\n",
      "EPOCH: [20/100] LOSS: 0.14795075356960297\n",
      "EPOCH: [30/100] LOSS: 0.08608484268188477\n",
      "EPOCH: [40/100] LOSS: 0.07147230952978134\n",
      "EPOCH: [50/100] LOSS: 0.06721200048923492\n",
      "EPOCH: [60/100] LOSS: 0.06420767307281494\n",
      "EPOCH: [70/100] LOSS: 0.061966411769390106\n",
      "EPOCH: [80/100] LOSS: 0.06023333966732025\n",
      "EPOCH: [90/100] LOSS: 0.0587436780333519\n"
     ]
    }
   ],
   "source": [
    "# Write Code !!\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    output = model(X_train)\n",
    "    \n",
    "    loss = criterion(output, y_train)\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'EPOCH: [{epoch}/{num_epochs}] LOSS: {loss.item()}')\n",
    "\n",
    "# 학습은 100번을 반복합니다 학습이 진행됨에 따라서 Loss가 감소하는 것을 볼수 있도록 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch(학습)에 따른 Loss감소를 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write Code !!\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습을 통해서 Loss를 감소시켰다면 이제는Test를 해봅니다.\n",
    "    테스트 할때는 학습의 의미가 없기때문에 Gradient Descent를 사용하지 않도록 합니다.\n",
    "    그 결과로 컴퓨터 Performance를 높이는 결과를 가져옵니다.\n",
    "    이때 우리가 테스트하는 데이타는 이미지가 아니고 단순 숫자 값으로 입력된다는 점을 잘 고려해야합니다.\n",
    "    출력된 값 중에서 가장 높은 값의 인덱스가 바로 target의 라벨이 됩니다.\n",
    "    \n",
    "    예측한 값과 정답을 일일이 비교해서 출력하고\n",
    "    총 30개의 Test 데이타 중에서 정확하게 맞춘 갯수를 최종적으로 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================예측값, 정답 출력===================\n",
      "1) 2 , 2\n",
      "2) 1 , 1\n",
      "3) 2 , 2\n",
      "4) 0 , 0\n",
      "5) 2 , 2\n",
      "6) 1 , 1\n",
      "7) 1 , 1\n",
      "8) 1 , 1\n",
      "9) 2 , 2\n",
      "10) 2 , 2\n",
      "11) 2 , 2\n",
      "12) 1 , 1\n",
      "13) 1 , 1\n",
      "14) 2 , 2\n",
      "15) 0 , 0\n",
      "16) 0 , 0\n",
      "17) 1 , 1\n",
      "18) 2 , 2\n",
      "19) 0 , 0\n",
      "20) 0 , 0\n",
      "21) 0 , 0\n",
      "22) 0 , 0\n",
      "23) 0 , 0\n",
      "24) 2 , 2\n",
      "25) 1 , 1\n",
      "26) 2 , 2\n",
      "27) 0 , 0\n",
      "28) 0 , 0\n",
      "29) 0 , 0\n",
      "30) 1 , 1\n",
      "30개의 Test 데이타 중에서 정답을 맞춘 갯수는 30 개 입니다!!\n"
     ]
    }
   ],
   "source": [
    " # Write Code!!\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _,predicted = torch.max(outputs, 1)\n",
    "    correct = (y_test == predicted).sum().item()\n",
    "\n",
    "print('================예측값, 정답 출력===================')\n",
    "for i in range(y_test.shape[0]):\n",
    "    print(f'{i+1}) {predicted[i]} , {y_test[i]}')\n",
    "print(f'{y_test.shape[0]}개의 Test 데이타 중에서 정답을 맞춘 갯수는 {correct} 개 입니다!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
