{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4fqi0NB_bsj"
      },
      "source": [
        "# Mount Google Drive Folder (/content/drive/My Drive/Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # 이 밑에있는 데이터 전부 mount 시키겠다\n",
        "\n",
        "# import user defined files \n",
        "import sys\n",
        "import_dir =\"/content/drive/My Drive/Colab Notebooks/2. Classification/pytorch-cifar\" \n",
        "sys.path.insert(0, import_dir) # 현재 경로 조정(다른파일 import할때 편하게 할 수 있음)\n",
        "\n",
        "# # import ipynb files...\n",
        "# !pip install import_ipynb \n",
        "# import import_ipynb\n",
        "\n",
        "%run '/content/drive/My Drive/Colab Notebooks/2. Classification/pytorch-cifar/dataset.ipynb' # custom dataset 정의한 주피터파일 import\n",
        "\n",
        "import easydict # argparse를 주피터에서 돌릴 수 있는 easydict\n",
        "\n",
        "\n",
        "# Debugging Tool\n",
        "import pdb\n",
        "\n",
        "# Download & Unzip Dataset (Move from google drive to local)\n",
        "%cp -r '/content/drive/My Drive/Colab Notebooks/Dataset/CIFAR10/cifar.tgz' '/content/sample_data' # 1에 있는 파일을 2에 넣는다.\n",
        "!tar -xvf  '/content/sample_data/cifar.tgz' # tgz파일 압축해제 -> content 밑에서 풀림\n",
        "\n",
        "# Initilize Additional parameters\n",
        "train_root = \"/content/cifar/train\" # 데이터 경로를 담은 변수\n",
        "test_root = \"/content/cifar/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q7zh5csGSS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e211e6-7146-4e7f-a31b-a714db688d38"
      },
      "source": [
        "'''Train CIFAR10 with PyTorch.'''\n",
        "# module import \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "from models import * # 폴더안에 모든걸 import하게 해줌\n",
        "# models 안에있는 init.py 가 먼저 돌아간다.\n",
        "# init.py에서 각각의 모델파일을 import 하고 있음 즉 init.py에 의해서 나머지 것들이 돌아감\n",
        "\n",
        "\n",
        "from utils import progress_bar\n",
        "\n",
        "\n",
        "'''\n",
        "# argparse 라이브러리를 사용하기 원한다면 터미널이나 다른 프레임워크에서 실행해야함\n",
        "# Removed Code (Because ipynb file does not support argparse)\n",
        "# Even removed, these lines are substitued by easydict code\n",
        "\n",
        "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
        "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "parser.add_argument('--resume', '-r', action='store_true',\n",
        "                    help='resume from checkpoint')\n",
        "args = parser.parse_args()\n",
        "'''\n",
        "args = easydict.EasyDict({ \"lr\": 0.1, \"resume\": True})  # args.key값으로 접근 가능\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' #  device설정-> cuda 사용가능하면 cuda사용 쓸수 없으면 CPU 사용\n",
        "\n",
        "best_acc = 0  # best accuracy를 넣을 변수 초기화\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "\n",
        "# 학습데이터에 쓰일 transform 정의\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4), # 32size로 랜덤하게 crop하고 left,right,top,bottom 테두리에 padding을 준다.\n",
        "    transforms.RandomHorizontalFlip(), # 50% 확률로 좌우반전\n",
        "    transforms.ToTensor(), # scaling, to tensor, channel dimension shift\n",
        "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # 명도나 채도등 각각의 다른 이미지의 환경을 정규화하기위함 / 앞은 평균 뒤는 표준편차\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(), # To tensor\n",
        "    # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # Normalize\n",
        "])\n",
        "\n",
        "# dataset.ipynb에서 정의한 custom Dataset클래스 생성\n",
        "trainset = Dataset(root=train_root, transforms=transform_train) \n",
        "\n",
        "# trainset을 Batch단위로 분할 + shuffle 등의 기능을 제공하는 DataLoader 생성\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=os.cpu_count(), drop_last=True) \n",
        "\n",
        "# num_workers=os.cpu_count() -> 데이터를 로딩하기위해 cpu개수만큼 사용한다.(data load multi processing)\n",
        "# drop_last=True -> 마지막 데이터들이 batch_size로 나누어 떨어지지 않으면 버림 (batch_size가 128이면 80개 남음 -> 사용x)\n",
        "\n",
        "# testset도 마찬가지\n",
        "testset = Dataset(root=test_root, transforms=transform_test)\n",
        "\n",
        "# testdata는 shuffle하지 않음\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=os.cpu_count(), drop_last=True)\n",
        "\n",
        "# cifar10 class 종류\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "# 사용할 모델 net으로 인스턴스화\n",
        "print('==> Building model..')\n",
        "# net = VGG('VGG19')\n",
        "# net = ResNet18()\n",
        "# net = PreActResNet18()\n",
        "# net = GoogLeNet()\n",
        "# net = DenseNet121()\n",
        "# net = ResNeXt29_2x64d()\n",
        "net = MobileNet() # 가장 가벼운 모델\n",
        "# net = MobileNetV2()\n",
        "# net = DPN92()\n",
        "# net = ShuffleNetG2()\n",
        "# net = SENet18()\n",
        "# net = ShuffleNetV2(1)\n",
        "# net = EfficientNetB0()\n",
        "# net = RegNetX_200MF()\n",
        "\n",
        "\n",
        "net = net.to(device)  # 모델을 gpu로 올림\n",
        "\n",
        "# gpu 있는거 다 쓰겠다.\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net) # 다수의 gpu로 병렬처리 (하지만 코랩은 gpu 1개)\n",
        "    cudnn.benchmark = True \n",
        "'''\n",
        "cudnn.benchmark = True ?\n",
        "\n",
        "내장된 cudnn 자동 튜너를 활성화하여, 하드웨어에 맞게 사용할 최상의 알고리즘(텐서 크기나 conv 연산에 맞게?)을 찾는다.\n",
        "입력 이미지 크기가 자주 변하지 않는다면, 초기 시간이 소요되지만 일반적으로 더 빠른 런타임의 효과를 볼 수 있다.\n",
        "'''\n",
        " \n",
        "# 현재 resume은 False\n",
        "if args.resume:\n",
        "    # Load checkpoint.\n",
        "    print('==> Resuming from checkpoint..')   \n",
        "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'   # 모델 정보를 저장한 적이 없으면 에러\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.pth') # 저장되어있는 모델정보(weights, best_acc, epoch) 불러오기\n",
        "    \n",
        "    net.load_state_dict(checkpoint['net']) # 모델의 weight들을 불러온 weight값으로 업데이트\n",
        "    best_acc = checkpoint['acc'] # 마찬가지로 best accuracy update\n",
        "    start_epoch = checkpoint['epoch'] # 마찬가지\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # multi class classification이므로 CrossEntropy 사용\n",
        "\n",
        "# optimizer로 Stochastic Gradient Descent 사용 / learning rate는 0.1  / weight_decay는 L2 regularization\n",
        "optimizer = optim.SGD(net.parameters(), lr=args.lr,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()  # train mode\n",
        "    # loss, correct, total 값을 저장할 변수 초기화\n",
        "    train_loss = 0  \n",
        "    correct = 0\n",
        "    total = 0    \n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader): \n",
        "        # inputs.shape : (128, 3, 32, 32) / targets.shape : (128) / len(trainloader) : 390 \n",
        "\n",
        "        inputs, targets = inputs.to(device), targets.to(device) # 데이터들을 gpu로 올림\n",
        "\n",
        "        # forward\n",
        "        optimizer.zero_grad() # optimizer 초기화\n",
        "\n",
        "\n",
        "        outputs = net(inputs) # 모델에 inputs을 넣어서 outputs를 얻음  / outputs.shape : (128, 10)\n",
        "        loss = criterion(outputs, targets)  # 128개의 image에 대한 L(w) 계산 \n",
        "\n",
        "        # backward\n",
        "        loss.backward() # 미분계산\n",
        "        optimizer.step() # 파라미터 업데이트\n",
        "\n",
        "        train_loss += loss.item() # 현재 batch의 L(w)를 train_loss에 계속 더함\n",
        "        _, predicted = outputs.max(1) # 각 label의 예측값 중에서 가장 큰값의 인덱스를 뽑음 (128,10) -> (128)   \n",
        "        total += targets.size(0) # 128씩 더함\n",
        "        correct += predicted.eq(targets).sum().item() # 예측이 맞는것들에 대한것만 correct에 더함 (128개중 맞은개수)\n",
        "        # pdb.set_trace()\n",
        "\n",
        "        # 한 epoch에서의 정보를 출력하기 위해 utils.py에 있는 progress_bar 함수 사용\n",
        "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "        #print(batch_idx,'/', len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "        #             % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "# Validation\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval() # evaluation mode\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            # batch_size : 100 / len(testloader) : 100\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # no backward            \n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1) # (100, 10) -> (100)\n",
        "            total += targets.size(0) # 100씩 더함\n",
        "            correct += predicted.eq(targets).sum().item() # 100개중 맞은개수만큼 더함\n",
        "\n",
        "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "            #print(batch_idx,'/', len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "            #             % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.   \n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'): \n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc # best_acc 업데이트\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch+2):\n",
        "    train(epoch)\n",
        "    test(epoch)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "==> Building model..\n",
            "==> Resuming from checkpoint..\n",
            "\n",
            "Epoch: 61\n",
            " [================================================================>]  Step: 41ms | Tot: 25s371ms | Loss: 0.599 | Acc: 79.808% (39840/49920) 390/390 \n",
            " [================================================================>]  Step: 17ms | Tot: 2s989ms | Loss: 0.632 | Acc: 79.160% (7916/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 62\n",
            " [================================================================>]  Step: 43ms | Tot: 24s714ms | Loss: 0.601 | Acc: 79.537% (39705/49920) 390/390 \n",
            " [================================================================>]  Step: 20ms | Tot: 2s963ms | Loss: 0.816 | Acc: 72.920% (7292/10000) 100/100 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6zhoF8JVYSY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "2c34d1a1-412d-4f4d-9111-196ae4f63b07"
      },
      "source": [
        "while 1:\r\n",
        "    continue\r\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-cfcb5e9e4b57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}